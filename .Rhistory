set.seed(2021)
#Setting parameter grid
param.mtry <- c(round((ncol(data)-2)/9),
round((ncol(data)-2)/3),
round((ncol(data)-2)/1.5))
param.nodesize <- c(3,5,7)
param.maxnodes <- c(0,10,100)
param <- expand.grid(param.mtry,param.nodesize,param.maxnodes)
#param <- split(param,1:nrow(param))
###############################
#Setting the training and test sets for 50 runs and
trainSets <- vector("list",nRun)
for (i in 1:nRun){
trainSets[[i]] <- caret::groupKFold(group = data$country,k = 39)
names(trainSets[[i]]) <- paste0("Run_",i,"_Fold_",1:length(trainSets[[i]]))
}
#aggregating them for computation efficiency
trainSets <- do.call(c, trainSets)
# testSets <- lapply(trainSets,function(trainSet){testSet <- setdiff(1:nrow(data),trainSet)})
#
# xtest <- lapply(testSets,function(testSet){dat <- data[testSet,-c(1,11)]})
# xtrain <- lapply(trainSets,function(trainSet){dat <- data[trainSet,-c(1,11)]})
# ytest <- lapply(testSets,function(testSet){dat <- data[testSet,11]})
# ytrain <- lapply(trainSets,function(trainSet){dat <- data[trainSet,11]})
RFdata <- lapply(trainSets,function(trainSet){
fold <- vector("list",6)
fold[[1]] <- trainSet
fold[[2]] <- setdiff(1:nrow(data),trainSet)
fold[[3]] <- data[-trainSet,-c(1,11)] #xtest
fold[[4]] <- data[trainSet,-c(1,11)] #xtrain
fold[[5]] <- data[-trainSet,11] #ytest
fold[[6]] <- data[trainSet,11] #ytrain
return(fold)
})
system.time({
coreNum <- parallel::detectCores()
clust <- parallel::makeCluster(coreNum-1)
for (i in 1:nrow(param)){
print(paste0("Running over parameter set ",i,"..."))
mtry <- as.numeric(param[i,1])
nodesize <- as.numeric(param[i,2])
if (param[i,3] == 0){maxnodes <- NULL}
else{maxnodes <- param[i,3]}
clusterExport(cl = clust,varlist = c("mtry","nodesize","maxnodes"))
rf <- parLapply(cl = clust,RFdata,function(fold){
xtest <- fold[[3]]
xtrain <- fold[[4]]
ytest <- fold[[5]]
ytrain <- fold[[6]]
res <- randomForest::randomForest(x = xtrain,y = ytrain,
xtest = xtest,ytest = ytest,
mtry = mtry,nodesize = nodesize,maxnodes = maxnodes,
keep.forest = TRUE,ntree = 500)
return(res)
})
print(paste0("Running over parameter set ",i,"...","DONE"))
assign(paste0('rf_',i),rf,pos = .GlobalEnv)
}
stopCluster(cl = clust)
})
View(trainSets)
View(param)
#dat <- "data_change.csv"
dat <- "Data_Y_Y_minus_One.csv" #Which version of the cleaned dataset to be used
nRun <- 5 #Number of separate runs
#-----------------------#
#   Loading libraries   #
#-----------------------#
packages <- c("ggplot2","randomForest","caret","dplyr","tidyr","parallel")
if (!requireNamespace("BiocManager", quietly = TRUE)){
install.packages("BiocManager")
BiocManager::install(version = "3.13")
}
for (p in packages){
if (!require(p, character.only = TRUE)){
BiocManager::install(p,update = FALSE)
if(!require(p,character.only = TRUE)) {stop("Package not found")}
}
}
detectCores()
#------------------#
#   Loading data   #
#------------------#
data <- read.csv(dat)
data <- data[,-1]
#--------------#
#   Analysis   #
#--------------#
set.seed(2021)
#Setting parameter grid
param.mtry <- c(round((ncol(data)-2)/9),
round((ncol(data)-2)/3),
round((ncol(data)-2)/1.5))
param.nodesize <- c(3,5,7)
param.maxnodes <- c(0,10,100)
param <- expand.grid(param.mtry,param.nodesize,param.maxnodes)
#param <- split(param,1:nrow(param))
###############################
#Setting the training and test sets for 50 runs and
trainSets <- vector("list",nRun)
for (i in 1:nRun){
trainSets[[i]] <- caret::groupKFold(group = data$country,k = 39)
names(trainSets[[i]]) <- paste0("Run_",i,"_Fold_",1:length(trainSets[[i]]))
}
#aggregating them for computation efficiency
trainSets <- do.call(c, trainSets)
# testSets <- lapply(trainSets,function(trainSet){testSet <- setdiff(1:nrow(data),trainSet)})
#
# xtest <- lapply(testSets,function(testSet){dat <- data[testSet,-c(1,11)]})
# xtrain <- lapply(trainSets,function(trainSet){dat <- data[trainSet,-c(1,11)]})
# ytest <- lapply(testSets,function(testSet){dat <- data[testSet,11]})
# ytrain <- lapply(trainSets,function(trainSet){dat <- data[trainSet,11]})
RFdata <- lapply(trainSets,function(trainSet){
fold <- vector("list",6)
fold[[1]] <- trainSet
fold[[2]] <- setdiff(1:nrow(data),trainSet)
fold[[3]] <- data[-trainSet,-c(1,11)] #xtest
fold[[4]] <- data[trainSet,-c(1,11)] #xtrain
fold[[5]] <- data[-trainSet,11] #ytest
fold[[6]] <- data[trainSet,11] #ytrain
return(fold)
})
system.time({
coreNum <- parallel::detectCores()
clust <- parallel::makeCluster(coreNum-1)
for (i in 1:nrow(param)){
print(paste0("Running over parameter set ",i,"..."))
mtry <- as.numeric(param[i,1])
nodesize <- as.numeric(param[i,2])
if (param[i,3] == 0){maxnodes <- NULL}
else{maxnodes <- param[i,3]}
clusterExport(cl = clust,varlist = c("mtry","nodesize","maxnodes"))
rf <- parLapply(cl = clust,RFdata,function(fold){
xtest <- fold[[3]]
xtrain <- fold[[4]]
ytest <- fold[[5]]
ytrain <- fold[[6]]
res <- randomForest::randomForest(x = xtrain,y = ytrain,
xtest = xtest,ytest = ytest,
mtry = mtry,nodesize = nodesize,maxnodes = maxnodes,
keep.forest = FALSE,ntree = 200)
return(res)
})
print(paste0("Running over parameter set ",i,"...","DONE"))
assign(paste0('rf_',i),rf,pos = .GlobalEnv)
}
stopCluster(cl = clust)
})
test <- vector('list',5)
test[[1]] <- rf_1
test[[2]] <- rf_2
View(test)
test2 <- test[[1]][[1]][['test']]
View(test2)
rf <- vector('list',nrow(param))
# rf <- lapply(trainSets,function(trainSet){
#   test <- data[-trainSet,]
#   train <- data[trainSet,]
#   res <- randomForest::randomForest(x = train[,-c(1,ncol(train))],y = train[,ncol(train)],
#                                     ntree = 10,keep.forest = TRUE)
#   return(res)
#
# })
############################################################
#Gathering prediction results
for (i in 1:length(rf)){
rf[[i]] <- eval(parse(text = paste0("rf_",i)))
}
View(rf)
# rf <- lapply(trainSets,function(trainSet){
#   test <- data[-trainSet,]
#   train <- data[trainSet,]
#   res <- randomForest::randomForest(x = train[,-c(1,ncol(train))],y = train[,ncol(train)],
#                                     ntree = 10,keep.forest = TRUE)
#   return(res)
#
# })
############################################################
#Gathering prediction results
cvPredByParam <- vector('list',length = nrow(param))
View(rf)
View(data)
View(RFdata)
rownames(data)[1]
dataTemp <- data[,ncol(data)]
dataTemp <- as.data.frame(data[,ncol(data)])
rep(0,2)
dataTemp <- matrix(rep(0,nrow(data)*nrow(param)),ncol = nrow(param))
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*nrow(param)),ncol = nrow(param)))
i = 1
pSet <- rf[[1]]
#   test <- data[-trainSet,]
#   train <- data[trainSet,]
#   res <- randomForest::randomForest(x = train[,-c(1,ncol(train))],y = train[,ncol(train)],
#                                     ntree = 10,keep.forest = TRUE)
#   return(res)
#
# })
############################################################
#Gathering prediction results
#cvPredByParam <- lapply(rf,function(pSet){
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(nrow(param)),ncol = nrow(param))))
#  for (i in 1:length(RFdata)){
samples <- RFdata[[i]][[2]]
predicted <- pSet[[i]][['test']][['predicted']]
temp <- data.frame(predicted,row.names = samples)
View(temp)
temp <- 1:nrow(data)
temp <- rep(NA,1:nrow(data))
temp <- rep(NA,nrow(data))
temp[samples] <- predicted
# rf <- lapply(trainSets,function(trainSet){
#   test <- data[-trainSet,]
#   train <- data[trainSet,]
#   res <- randomForest::randomForest(x = train[,-c(1,ncol(train))],y = train[,ncol(train)],
#                                     ntree = 10,keep.forest = TRUE)
#   return(res)
#
# })
############################################################
#Gathering prediction results
cvPredByParam <- lapply(rf,function(pSet){
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(length(pSet)),ncol = nrow(param))))
for (i in 1:length(RFdata)){
samples <- RFdata[[i]][[2]]
predicted <- pSet[[i]][['test']][['predicted']]
temp <- rep(NA,nrow(data))
temp[samples] <- predicted
dataTemp[,i] <- temp
}
colnames(dataTemp) <- paste0('p_set_',1:length(pSet))
})
View(cvPredByParam)
# rf <- lapply(trainSets,function(trainSet){
#   test <- data[-trainSet,]
#   train <- data[trainSet,]
#   res <- randomForest::randomForest(x = train[,-c(1,ncol(train))],y = train[,ncol(train)],
#                                     ntree = 10,keep.forest = TRUE)
#   return(res)
#
# })
############################################################
#Gathering prediction results
cvPredByParam <- lapply(rf,function(pSet){
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(length(pSet)),ncol = nrow(param))))
for (i in 1:length(RFdata)){
samples <- RFdata[[i]][[2]]
predicted <- pSet[[i]][['test']][['predicted']]
temp <- rep(NA,nrow(data))
temp[samples] <- predicted
dataTemp[,i] <- temp
}
colnames(dataTemp) <- paste0('p_set_',1:length(pSet))
return(dataTemp)
})
View(cvPredByParam)
# rf <- lapply(trainSets,function(trainSet){
#   test <- data[-trainSet,]
#   train <- data[trainSet,]
#   res <- randomForest::randomForest(x = train[,-c(1,ncol(train))],y = train[,ncol(train)],
#                                     ntree = 10,keep.forest = TRUE)
#   return(res)
#
# })
############################################################
#Gathering prediction results
cvPredByParam <- lapply(rf,function(pSet){
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(length(pSet)),ncol = length(pSet))))
for (i in 1:length(RFdata)){
samples <- RFdata[[i]][[2]]
predicted <- pSet[[i]][['test']][['predicted']]
temp <- rep(NA,nrow(data))
temp[samples] <- predicted
dataTemp[,i] <- temp
}
colnames(dataTemp) <- paste0('p_set_',1:length(pSet))
return(dataTemp)
})
View(cvPredByParam)
length(pSet)
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(length(pSet)),ncol = length(pSet))))
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(length(rf)),ncol = length(rf))))
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(length(rf)),ncol = length(rf))))
dataTemp <- matrix(rep(0,nrow(data)*(length(rf)),ncol = length(rf)))
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(length(rf))),ncol = length(rf)))
# rf <- lapply(trainSets,function(trainSet){
#   test <- data[-trainSet,]
#   train <- data[trainSet,]
#   res <- randomForest::randomForest(x = train[,-c(1,ncol(train))],y = train[,ncol(train)],
#                                     ntree = 10,keep.forest = TRUE)
#   return(res)
#
# })
############################################################
#Gathering prediction results
cvPredByParam <- lapply(rf,function(pSet){
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(length(rf))),ncol = length(rf)))
for (i in 1:length(RFdata)){
samples <- RFdata[[i]][[2]]
predicted <- pSet[[i]][['test']][['predicted']]
temp <- rep(NA,nrow(data))
temp[samples] <- predicted
dataTemp[,i] <- temp
}
colnames(dataTemp) <- paste0('p_set_',1:length(pSet))
return(dataTemp)
})
View(cvPredByParam)
cvPredByParam <- lapply(rf,function(pSet){
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(length(rf))),ncol = length(rf)))
for (i in 1:length(RFdata)){
samples <- RFdata[[i]][[2]]
predicted <- pSet[[i]][['test']][['predicted']]
temp <- rep(NA,nrow(data))
temp[samples] <- predicted
dataTemp[,i] <- temp
}
colnames(dataTemp) <- names(RFdata)
return(dataTemp)
})
names(cvPredByParam) <- paste0('p_set_',1:length(pSet))
names(cvPredByParam) <- paste0('p_set_',1:length(rf))
View(cvPredByParam)
View(cvPredByParam[["p_set_1"]])
test <- sd(c(1,5))
test <- sd(cvPredByParam[[1]][1,],na.rm = TRUE)
View(rf_1)
#dat <- "data_change.csv"
dat <- "Data_Y_Y_minus_One.csv" #Which version of the cleaned dataset to be used
nRun <- 10 #Number of separate runs
#-----------------------#
#   Loading libraries   #
#-----------------------#
packages <- c("ggplot2","randomForest","caret","dplyr","tidyr","parallel")
if (!requireNamespace("BiocManager", quietly = TRUE)){
install.packages("BiocManager")
BiocManager::install(version = "3.13")
}
for (p in packages){
if (!require(p, character.only = TRUE)){
BiocManager::install(p,update = FALSE)
if(!require(p,character.only = TRUE)) {stop("Package not found")}
}
}
sample(39,size = 39,replace = TRUE)
save(c(nRun,p),file = "test.RData")
save(nRun,p,file = "test.RData")
load("test.RData")
t <-  load("test.RData")
#------------------#
#   Loading data   #
#------------------#
data <- read.csv(dat)
data <- data[,-1]
#--------------#
#   Analysis   #
#--------------#
set.seed(2021)
#Setting parameter grid
param.mtry <- c(round((ncol(data)-2)/9),
round((ncol(data)-2)/3),
round((ncol(data)-2)/1.5))
param.nodesize <- c(3,5,7)
param.maxnodes <- c(0,10,100)
param <- expand.grid(param.mtry,param.nodesize,param.maxnodes)
#param <- split(param,1:nrow(param))
###############################
#Setting the training and test sets for 50 runs and
trainSets <- vector("list",nRun)
for (i in 1:nRun){
trainSets[[i]] <- caret::groupKFold(group = data$country,k = 39)
names(trainSets[[i]]) <- paste0("Run_",i,"_Fold_",1:length(trainSets[[i]]))
}
#aggregating them for computation efficiency
trainSets <- do.call(c, trainSets)
# testSets <- lapply(trainSets,function(trainSet){testSet <- setdiff(1:nrow(data),trainSet)})
#
# xtest <- lapply(testSets,function(testSet){dat <- data[testSet,-c(1,11)]})
# xtrain <- lapply(trainSets,function(trainSet){dat <- data[trainSet,-c(1,11)]})
# ytest <- lapply(testSets,function(testSet){dat <- data[testSet,11]})
# ytrain <- lapply(trainSets,function(trainSet){dat <- data[trainSet,11]})
RFdata <- lapply(trainSets,function(trainSet){
fold <- vector("list",6)
fold[[1]] <- trainSet
fold[[2]] <- setdiff(1:nrow(data),trainSet)
fold[[3]] <- data[-trainSet,-c(1,11)] #xtest
fold[[4]] <- data[trainSet,-c(1,11)] #xtrain
fold[[5]] <- data[-trainSet,11] #ytest
fold[[6]] <- data[trainSet,11] #ytrain
return(fold)
})
#----------------#
#dat <- "data_change.csv"
dat <- "Data_Y_Y_minus_One.csv" #Which version of the cleaned dataset to be used
nRun <- 2 #Number of separate runs
#-----------------------#
#   Loading libraries   #
#-----------------------#
packages <- c("ggplot2","randomForest","caret","dplyr","tidyr","parallel")
if (!requireNamespace("BiocManager", quietly = TRUE)){
install.packages("BiocManager")
BiocManager::install(version = "3.13")
}
for (p in packages){
if (!require(p, character.only = TRUE)){
BiocManager::install(p,update = FALSE)
if(!require(p,character.only = TRUE)) {stop("Package not found")}
}
}
#------------------#
#   Loading data   #
#------------------#
data <- read.csv(dat)
data <- data[,-1]
#--------------#
#   Analysis   #
#--------------#
set.seed(2021)
#Setting parameter grid
param.mtry <- c(round((ncol(data)-2)/9),
round((ncol(data)-2)/3),
round((ncol(data)-2)/1.5))
param.nodesize <- c(3,5,7)
param.maxnodes <- c(0,10,100)
param <- expand.grid(param.mtry,param.nodesize,param.maxnodes)
#param <- split(param,1:nrow(param))
###############################
#Setting the training and test sets for 50 runs and
trainSets <- vector("list",nRun)
for (i in 1:nRun){
trainSets[[i]] <- caret::groupKFold(group = data$country,k = 39)
names(trainSets[[i]]) <- paste0("Run_",i,"_Fold_",1:length(trainSets[[i]]))
}
#aggregating them for computation efficiency
trainSets <- do.call(c, trainSets)
# testSets <- lapply(trainSets,function(trainSet){testSet <- setdiff(1:nrow(data),trainSet)})
#
# xtest <- lapply(testSets,function(testSet){dat <- data[testSet,-c(1,11)]})
# xtrain <- lapply(trainSets,function(trainSet){dat <- data[trainSet,-c(1,11)]})
# ytest <- lapply(testSets,function(testSet){dat <- data[testSet,11]})
# ytrain <- lapply(trainSets,function(trainSet){dat <- data[trainSet,11]})
RFdata <- lapply(trainSets,function(trainSet){
fold <- vector("list",6)
fold[[1]] <- trainSet
fold[[2]] <- setdiff(1:nrow(data),trainSet)
fold[[3]] <- data[-trainSet,-c(1,11)] #xtest
fold[[4]] <- data[trainSet,-c(1,11)] #xtrain
fold[[5]] <- data[-trainSet,11] #ytest
fold[[6]] <- data[trainSet,11] #ytrain
return(fold)
})
system.time({
coreNum <- parallel::detectCores()
clust <- parallel::makeCluster(coreNum-1)
rf <- vector('list',nrow(param))
for (i in 1:nrow(param)){
print(paste0("Running over parameter set ",i,"..."))
mtry <- as.numeric(param[i,1])
nodesize <- as.numeric(param[i,2])
if (param[i,3] == 0){maxnodes <- NULL}
else{maxnodes <- param[i,3]}
clusterExport(cl = clust,varlist = c("mtry","nodesize","maxnodes"))
rf[[i]] <- parLapply(cl = clust,RFdata,function(fold){
xtest <- fold[[3]]
xtrain <- fold[[4]]
ytest <- fold[[5]]
ytrain <- fold[[6]]
res <- randomForest::randomForest(x = xtrain,y = ytrain,
xtest = xtest,ytest = ytest,
mtry = mtry,nodesize = nodesize,maxnodes = maxnodes,
keep.forest = FALSE,ntree = 20)
return(res)
})
print(paste0("Running over parameter set ",i,"...","DONE"))
#assign(paste0('rf_',i),rf,pos = .GlobalEnv)
}
stopCluster(cl = clust)
})
View(rf)
randomForest::importance(rf[[1]][[1]])
system.time({
coreNum <- parallel::detectCores()
clust <- parallel::makeCluster(coreNum-1)
rf <- vector('list',nrow(param))
for (i in 1:nrow(param)){
print(paste0("Running over parameter set ",i,"..."))
mtry <- as.numeric(param[i,1])
nodesize <- as.numeric(param[i,2])
if (param[i,3] == 0){maxnodes <- NULL}
else{maxnodes <- param[i,3]}
clusterExport(cl = clust,varlist = c("mtry","nodesize","maxnodes"))
rf[[i]] <- parLapply(cl = clust,RFdata,function(fold){
xtest <- fold[[3]]
xtrain <- fold[[4]]
ytest <- fold[[5]]
ytrain <- fold[[6]]
res <- randomForest::randomForest(x = xtrain,y = ytrain,
xtest = xtest,ytest = ytest,
mtry = mtry,nodesize = nodesize,maxnodes = maxnodes,
keep.forest = FALSE,ntree = 20,importance = TRUE)
return(res)
})
print(paste0("Running over parameter set ",i,"...","DONE"))
#assign(paste0('rf_',i),rf,pos = .GlobalEnv)
}
stopCluster(cl = clust)
})
View(rf)
View(RFdata)
View(rf)
randomForest::importance(rf[[1]][[1]])
barplot(randomForest::importance(rf[[1]][[1]])[,2])
