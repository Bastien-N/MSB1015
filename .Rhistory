<<<<<<< HEAD
years <- unique(dataTemp$year)
for (ii in 9){
yearsTemp <- years[(1+(i-1)*3):(i*3)]
dataTemp2 <- dataTemp[dataTemp$year %in% yearsTemp,]
if (nrow(dataTemp2) == 3){
dataTemp2 <- data.frame(dataTemp2[1,1],
paste0(substr(yearsTemp[1],1,4),'_to_',substr(yearsTemp[3],1,4)),
t(colSums(dataTemp2[,-c(1,2)])))
colnames(dataTemp2) <- colnames(DataChange)
if (ii == 1){
dataTemp3 <- dataTemp2
}
else{
dataTemp3 <- rbind(dataTemp3,dataTemp2)
}
}
}
if (i == 1){DataAggThree <- dataTemp3}
else{DataAggThree <- rbind(DataAggThree,dataTemp3)}
}
View(DataAggThree)
#Aggregating years:
#Per three years
dataTemp <- dataTemp2 <- dataTemp3 <- DataAggThree<- NULL
#Aggregating years:
#Per three years
dataTemp <- dataTemp2 <- dataTemp3 <- DataAggThree<- NULL
for (i in 1:length(countries)){
dataTemp <- DataChange[DataChange$country == countries[i],]
years <- unique(dataTemp$year)
for (ii in 9){
yearsTemp <- years[(1+(ii-1)*3):(ii*3)]
dataTemp2 <- dataTemp[dataTemp$year %in% yearsTemp,]
if (nrow(dataTemp2) == 3){
dataTemp2 <- data.frame(dataTemp2[1,1],
paste0(substr(yearsTemp[1],1,4),'_to_',substr(yearsTemp[3],1,4)),
t(colSums(dataTemp2[,-c(1,2)])))
colnames(dataTemp2) <- colnames(DataChange)
if (ii == 1){
dataTemp3 <- dataTemp2
}
else{
dataTemp3 <- rbind(dataTemp3,dataTemp2)
}
}
}
if (i == 1){DataAggThree <- dataTemp3}
else{DataAggThree <- rbind(DataAggThree,dataTemp3)}
}
View(DataAggThree)
#Aggregating years:
#Per three years
dataTemp <- dataTemp2 <- dataTemp3 <- DataAggThree<- NULL
for (i in 1:length(countries)){
dataTemp <- DataChange[DataChange$country == countries[i],]
years <- unique(dataTemp$year)
for (ii in 1:9){
yearsTemp <- years[(1+(ii-1)*3):(ii*3)]
dataTemp2 <- dataTemp[dataTemp$year %in% yearsTemp,]
if (nrow(dataTemp2) == 3){
dataTemp2 <- data.frame(dataTemp2[1,1],
paste0(substr(yearsTemp[1],1,4),'_to_',substr(yearsTemp[3],1,4)),
t(colSums(dataTemp2[,-c(1,2)])))
colnames(dataTemp2) <- colnames(DataChange)
if (ii == 1){
dataTemp3 <- dataTemp2
}
else{
dataTemp3 <- rbind(dataTemp3,dataTemp2)
}
}
}
if (i == 1){DataAggThree <- dataTemp3}
else{DataAggThree <- rbind(DataAggThree,dataTemp3)}
}
View(DataAggThree)
View(DataAggThree)
pcaDat <- DataAggThree[,-c(1,2)]
pcaDat <- pca(pcaDat,nPcs = 6,scale = "pareto")
substring <- substr(DataAggThree$country,1,2)
pcaRes <- data.frame(DataAggThree,pcaDat@scores,substring)
ggplot(pcaRes,aes(x = PC1,y = PC2,color = copdDalys)) +
geom_text(aes(label = substring))
#Exploring relationship
for (var in colnames(DataAggThree)[-c(1,2,11)]){
plot(DataAggThree[,var],DataAggThree$copdDalys,xlab = var,ylab = "COPD Dalys")
}
#Per nine years
dataTemp <- dataTemp2 <- dataTemp3 <- DataAggNine<- NULL
for (i in 1:length(countries)){
dataTemp <- DataChange[DataChange$country == countries[i],]
years <- unique(dataTemp$year)
for (ii in 1:3){
yearsTemp <- years[(1+(ii-1)*9):(ii*9)]
dataTemp2 <- dataTemp[dataTemp$year %in% yearsTemp,]
if (nrow(dataTemp2) == 9){
dataTemp2 <- data.frame(dataTemp2[1,1],
paste0(substr(yearsTemp[1],1,4),'_to_',substr(yearsTemp[3],1,4)),
t(colSums(dataTemp2[,-c(1,2)])))
colnames(dataTemp2) <- colnames(DataChange)
if (ii == 1){
dataTemp3 <- dataTemp2
}
else{
dataTemp3 <- rbind(dataTemp3,dataTemp2)
}
}
}
if (i == 1){DataAggNine <- dataTemp3}
else{DataAggNine <- rbind(DataAggNine,dataTemp3)}
}
#PCA
pcaDat <- DataAggNine[,-c(1,2)]
pcaDat <- pca(pcaDat,nPcs = 6,scale = "pareto")
substring <- substr(DataAggNine$country,1,2)
pcaRes <- data.frame(DataAggNine,pcaDat@scores,substring)
ggplot(pcaRes,aes(x = PC1,y = PC2,color = copdDalys)) +
geom_text(aes(label = substring))
#Exploring relationship
for (var in colnames(DataAggNine)[-c(1,2,11)]){
plot(DataAggNine[,var],DataAggNine$copdDalys,xlab = var,ylab = "COPD Dalys")
}
hist(DataChange$copdDalys)
hist(DataAggNine$copdDalys)
hist(DataAggThree$copdDalys)
#----------------#
#   User input   #
#----------------#
#-----------------------#
#   Loading libraries   #
#-----------------------#
packages <- c("ggplot2","tidyr","pcaMethods","ggfortify")
=======
set.seed(2021)
#Setting parameter grid
param.mtry <- c(round((ncol(data)-2)/9),
round((ncol(data)-2)/3),
round((ncol(data)-2)/1.5))
param.nodesize <- c(3,5,7)
param.maxnodes <- c(0,10,100)
param <- expand.grid(param.mtry,param.nodesize,param.maxnodes)
#param <- split(param,1:nrow(param))
###############################
#Setting the training and test sets for 50 runs and
trainSets <- vector("list",nRun)
for (i in 1:nRun){
trainSets[[i]] <- caret::groupKFold(group = data$country,k = 39)
names(trainSets[[i]]) <- paste0("Run_",i,"_Fold_",1:length(trainSets[[i]]))
}
#aggregating them for computation efficiency
trainSets <- do.call(c, trainSets)
# testSets <- lapply(trainSets,function(trainSet){testSet <- setdiff(1:nrow(data),trainSet)})
#
# xtest <- lapply(testSets,function(testSet){dat <- data[testSet,-c(1,11)]})
# xtrain <- lapply(trainSets,function(trainSet){dat <- data[trainSet,-c(1,11)]})
# ytest <- lapply(testSets,function(testSet){dat <- data[testSet,11]})
# ytrain <- lapply(trainSets,function(trainSet){dat <- data[trainSet,11]})
RFdata <- lapply(trainSets,function(trainSet){
fold <- vector("list",6)
fold[[1]] <- trainSet
fold[[2]] <- setdiff(1:nrow(data),trainSet)
fold[[3]] <- data[-trainSet,-c(1,11)] #xtest
fold[[4]] <- data[trainSet,-c(1,11)] #xtrain
fold[[5]] <- data[-trainSet,11] #ytest
fold[[6]] <- data[trainSet,11] #ytrain
return(fold)
})
system.time({
coreNum <- parallel::detectCores()
clust <- parallel::makeCluster(coreNum-1)
for (i in 1:nrow(param)){
print(paste0("Running over parameter set ",i,"..."))
mtry <- as.numeric(param[i,1])
nodesize <- as.numeric(param[i,2])
if (param[i,3] == 0){maxnodes <- NULL}
else{maxnodes <- param[i,3]}
clusterExport(cl = clust,varlist = c("mtry","nodesize","maxnodes"))
rf <- parLapply(cl = clust,RFdata,function(fold){
xtest <- fold[[3]]
xtrain <- fold[[4]]
ytest <- fold[[5]]
ytrain <- fold[[6]]
res <- randomForest::randomForest(x = xtrain,y = ytrain,
xtest = xtest,ytest = ytest,
mtry = mtry,nodesize = nodesize,maxnodes = maxnodes,
keep.forest = TRUE,ntree = 500)
return(res)
})
print(paste0("Running over parameter set ",i,"...","DONE"))
assign(paste0('rf_',i),rf,pos = .GlobalEnv)
}
stopCluster(cl = clust)
})
View(trainSets)
View(param)
#dat <- "data_change.csv"
dat <- "Data_Y_Y_minus_One.csv" #Which version of the cleaned dataset to be used
nRun <- 5 #Number of separate runs
#-----------------------#
#   Loading libraries   #
#-----------------------#
packages <- c("ggplot2","randomForest","caret","dplyr","tidyr","parallel")
>>>>>>> 9991e1ee1b29748f70c2f494ab496594f9862723
if (!requireNamespace("BiocManager", quietly = TRUE)){
install.packages("BiocManager")
BiocManager::install(version = "3.13")
}
for (p in packages){
if (!require(p, character.only = TRUE)){
BiocManager::install(p,update = FALSE)
if(!require(p,character.only = TRUE)) {stop("Package not found")}
}
}
detectCores()
#------------------#
#   Loading data   #
#------------------#
data <- read.csv(dat)
data <- data[,-1]
#--------------#
#   Analysis   #
#--------------#
set.seed(2021)
#Setting parameter grid
param.mtry <- c(round((ncol(data)-2)/9),
round((ncol(data)-2)/3),
round((ncol(data)-2)/1.5))
param.nodesize <- c(3,5,7)
param.maxnodes <- c(0,10,100)
param <- expand.grid(param.mtry,param.nodesize,param.maxnodes)
#param <- split(param,1:nrow(param))
###############################
#Setting the training and test sets for 50 runs and
trainSets <- vector("list",nRun)
for (i in 1:nRun){
trainSets[[i]] <- caret::groupKFold(group = data$country,k = 39)
names(trainSets[[i]]) <- paste0("Run_",i,"_Fold_",1:length(trainSets[[i]]))
}
#aggregating them for computation efficiency
trainSets <- do.call(c, trainSets)
# testSets <- lapply(trainSets,function(trainSet){testSet <- setdiff(1:nrow(data),trainSet)})
#
# xtest <- lapply(testSets,function(testSet){dat <- data[testSet,-c(1,11)]})
# xtrain <- lapply(trainSets,function(trainSet){dat <- data[trainSet,-c(1,11)]})
# ytest <- lapply(testSets,function(testSet){dat <- data[testSet,11]})
# ytrain <- lapply(trainSets,function(trainSet){dat <- data[trainSet,11]})
RFdata <- lapply(trainSets,function(trainSet){
fold <- vector("list",6)
fold[[1]] <- trainSet
fold[[2]] <- setdiff(1:nrow(data),trainSet)
fold[[3]] <- data[-trainSet,-c(1,11)] #xtest
fold[[4]] <- data[trainSet,-c(1,11)] #xtrain
fold[[5]] <- data[-trainSet,11] #ytest
fold[[6]] <- data[trainSet,11] #ytrain
return(fold)
})
system.time({
coreNum <- parallel::detectCores()
clust <- parallel::makeCluster(coreNum-1)
for (i in 1:nrow(param)){
print(paste0("Running over parameter set ",i,"..."))
mtry <- as.numeric(param[i,1])
nodesize <- as.numeric(param[i,2])
if (param[i,3] == 0){maxnodes <- NULL}
else{maxnodes <- param[i,3]}
clusterExport(cl = clust,varlist = c("mtry","nodesize","maxnodes"))
rf <- parLapply(cl = clust,RFdata,function(fold){
xtest <- fold[[3]]
xtrain <- fold[[4]]
ytest <- fold[[5]]
ytrain <- fold[[6]]
res <- randomForest::randomForest(x = xtrain,y = ytrain,
xtest = xtest,ytest = ytest,
mtry = mtry,nodesize = nodesize,maxnodes = maxnodes,
keep.forest = FALSE,ntree = 200)
return(res)
})
print(paste0("Running over parameter set ",i,"...","DONE"))
assign(paste0('rf_',i),rf,pos = .GlobalEnv)
}
stopCluster(cl = clust)
})
<<<<<<< HEAD
dat <- pivot_longer(dat,cols = -1,names_to = "year", values_to = "Value")
dat$year <- as.numeric(dat$year)
return(dat)
})
#extracting needed GBD data
copdDailys <- gbd_extract(datasets[[9]],"DALYs (Disability-Adjusted Life Years)",
"Number","Chronic obstructive pulmonary disease",
commonCountries,
1990:2017)
datasetsClean[[9]] <- copdDailys
names(datasetsClean)[9] <- "copdDalys"
#Combining the data
Data <- data.frame(datasetsClean[[1]],datasetsClean[[2]][,3],
datasetsClean[[3]][,3],datasetsClean[[4]][,3],datasetsClean[[5]][,3],
datasetsClean[[6]][,3],datasetsClean[[7]][,3],datasetsClean[[8]][,3],
datasetsClean[[9]][,3])
colnames(Data)[-c(1,2)] <- names(datasetsClean)
# #check countries with too many missing values over too many variables
# rowWiseNa <- apply(naDat[,-c(1,2)],1,sum)
# missingDataCountries <- unique(naDat[(rowWiseNa / 9) > 0.3,1])
# Data <- Data[!(Data$country %in% missingDataCountries),]
#Removing all rows with missing values
naDat <- is.na.data.frame(Data)
naDat <- rowSums(naDat) == 0
Data <- Data[naDat,]
pcaDat <- Data[,-c(1,2)]
pcaDat <- pca(pcaDat,nPcs = 6,scale = "pareto")
substring <- substr(Data$country,1,2)
pcaRes <- data.frame(Data[,c(1,2)],pcaDat@scores,substring)
ggplot(pcaRes,aes(x = PC1,y = PC2,color = year)) +
geom_text(aes(label = substring))
#Transforming data into change (year-previous year)
countries <- unique(Data$country)
for (i in 1:length(countries)){
dataTemp <- Data[Data$country == countries[i],]
dataTemp2 <- dataTemp[-nrow(dataTemp),]
dataTemp <- dataTemp[-1,]
year <- paste0(dataTemp2$year,"_to_",dataTemp$year)
dataTemp3 <- as.data.frame(mapply('-',dataTemp[,-c(1,2)],dataTemp2[,-c(1,2)]))
dataTemp3 <- data.frame(rep(countries[i],nrow(dataTemp)),year,dataTemp3)
colnames(dataTemp3)[1] <- "country"
if (i == 1){
DataChange <- dataTemp3
}
else{
DataChange <- rbind(DataChange,dataTemp3)
}
}
# pcaDat <- DataChange[,-c(1,2)]
# pcaDat <- pca(pcaDat,nPcs = 6,scale = "pareto")
# substring <- substr(DataChange$country,1,2)
# pcaRes <- data.frame(DataChange,pcaDat@scores, substring)
# plot(pcaDat@loadings)
# ggplot(pcaRes,aes(x = PC1,y = PC2,color = copdDalys)) +
#   geom_text(aes(label = substring)) +
#   geom_segment(data=pcaD, aes(x=0, y=0, xend=PC1, yend=PC2)
#                , arrow=arrow(length=unit(0.2,"cm")), alpha=0.25)
# ggbiplot(as.data.frame(pcaDat@scores),as.data.frame(pcaDat@loadings))
pcaDat <- DataChange[,-c(1,2)]
pcaDat <- prcomp(pcaDat, scale. = TRUE,center = TRUE)
substring <- substr(DataChange$country,1,2)
pcaRes <- data.frame(DataChange, substring)
autoplot(pcaDat,data = pcaRes , label = TRUE,shape = FALSE,label.label = 'substring',
label.alpha = 0.6,loadings = TRUE,loadings.label = TRUE)
autoplot(pcaDat,data = pcaRes , label = TRUE,shape = FALSE,label.label = 'substring',
label.alpha = 0.6,loadings = TRUE,loadings.label = TRUE)
#Creating complete shifted model Y + Y-1
for (i in 1:length(countries)){
Y <- DataChange[DataChange$country == countries[i],]
Y <- Y[-1,]
YminusOne <- DataChange[DataChange$country == countries[i],]
YminusOne <- YminusOne[-nrow(YminusOne),-c(1,2)]
colnames(YminusOne) <- paste0("prev_",colnames(YminusOne))
dataTemp <- cbind(Y,YminusOne)
if (i == 1){DataY_YminusOne <- dataTemp
}else {DataY_YminusOne <-  rbind(DataY_YminusOne ,dataTemp)}
}
pcaDat <- DataY_YminusOne[,-c(1,2)]
pcaDat <- prcomp(pcaDat, scale. = TRUE,center = TRUE)
substring <- substr(DataY_YminusOne$country,1,2)
pcaRes <- data.frame(DataY_YminusOne, substring)
autoplot(pcaDat,data = pcaRes , label = TRUE,shape = FALSE,label.label = 'substring',
label.alpha = 0.6,loadings = TRUE,loadings.label = TRUE)
#-----------------------#
#   Loading libraries   #
#-----------------------#
packages <- c("ggplot2","tidyr","pcaMethods","ggfortify","randomForest")
if (!requireNamespace("BiocManager", quietly = TRUE)){
install.packages("BiocManager")
BiocManager::install(version = "3.13")
}
for (p in packages){
if (!require(p, character.only = TRUE)){
BiocManager::install(p,update = FALSE)
if(!require(p,character.only = TRUE)) {stop("Package not found")}
}
}
View(DataY_YminusOne)
#Using unsupervised random forest to identify outliers
urf <- randomForest::randomForest(x = DataY_YminusOne[,-c(1,2)])
#Using unsupervised random forest to identify outliers
urf <- randomForest::randomForest(x = DataY_YminusOne[,-c(1,2)],do.trace = TRUE)
View(urf)
randomForest::MDSplot(urf)
randomForest::MDSplot(urf,fac = DataY_YminusOne[,ncol(DataY_YminusOne)])
randomForest::MDSplot(urf,fac = DataY_YminusOne$country)
randomForest::MDSplot(urf,fac = DataY_YminusOne$prev_copdDalys)
out <- randomForest::outlier(urf)
out <- randomForest::outlier(urf,DataY_YminusOne$country)
plot(out)
out <- randomForest::outlier(urf,DataY_YminusOne$country)
plot(out)
out <- randomForest::outlier(urf)
plot(out)
urf <- randomForest::randomForest(x = DataY_YminusOne[,-c(1,2)])
out <- randomForest::outlier(urf)
plot(out)
names(max(out))
names(which(max(out) == out))
out[1]
out[1:5]
out <- randomForest::outlier(urf,cl = row.names(DataY_YminusOne))
names(which(max(out) == out))
out[1]
out <- randomForest::outlier(urf,cl =DataY_YminusOne$country)
out[1]
names(out) <- 1:length(out)
out[1]
autoplot(pcaDat,data = pcaRes , label = TRUE,shape = FALSE,label.label = 'substring',
label.alpha = 0.6,loadings = TRUE,loadings.label = TRUE)
largestOut <- sort(out,decreasing = TRUE)[1:5]
largestOut
DataY_YminusOne[names(largestOut),1]
largestOut <- sort(out,decreasing = FALSE)[1:5]
DataY_YminusOne[names(largestOut),1]
urf <- randomForest::randomForest(x = DataChange[,-c(1,2)],ntree = 600)
out <- randomForest::outlier(urf)
names(out) <- 1:length(out)
largestOut <- sort(out,decreasing = TRUE)[1:5]
DataChange[names(largestOut),1]
urf <- randomForest::randomForest(x = DataChange[,-c(1,2)],ntree = 600)
out <- randomForest::outlier(urf)
names(out) <- 1:length(out)
largestOut <- sort(out,decreasing = TRUE)[1:5]
DataChange[names(largestOut),1]
urf <- randomForest::randomForest(x = DataChange[,-c(1,2)],ntree = 600)
out <- randomForest::outlier(urf)
names(out) <- 1:length(out)
largestOut <- sort(out,decreasing = TRUE)[1:5]
DataChange[names(largestOut),1]
pcaDat <- DataChange[,-c(1,2)]
pcaDat <- prcomp(pcaDat, scale. = TRUE,center = TRUE)
substring <- substr(DataChange$country,1,2)
pcaRes <- data.frame(DataChange, substring)
autoplot(pcaDat,data = pcaRes , label = TRUE,shape = FALSE,label.label = 'substring',
label.alpha = 0.6,loadings = TRUE,loadings.label = TRUE)
plot(out)
#-----------------------#
#   Loading libraries   #
#-----------------------#
packages <- c("ggplot2","tidyr","pcaMethods","ggfortify","randomForest","solitude")
if (!requireNamespace("BiocManager", quietly = TRUE)){
install.packages("BiocManager")
BiocManager::install(version = "3.13")
}
for (p in packages){
if (!require(p, character.only = TRUE)){
BiocManager::install(p,update = FALSE)
if(!require(p,character.only = TRUE)) {stop("Package not found")}
}
}
library(solitude)
isolationForest
urf <- randomForest::randomForest(x = DataChange[,-c(1,2)],ntree = 600)
out <- randomForest::outlier(urf)
names(out) <- 1:length(out)
largestOut <- sort(out,decreasing = TRUE)[1:5]
DataChange[names(largestOut),1]
urf <- randomForest::randomForest(x = DataChange[,-c(1,2)])
out <- randomForest::outlier(urf)
names(out) <- 1:length(out)
largestOut <- sort(out,decreasing = TRUE)[1:5]
DataChange[names(largestOut),1]
outlying <- rep(FALSE,nrow(DataChange))
outlying[names(largestOut)] <- TRUE
pcaRes <- data.frame(pcaRes,outlying)
outlying <- rep(FALSE,nrow(DataChange))
outlying[names(largestOut)] <- TRUE
names(largestOut)
outlying <- rep(FALSE,nrow(DataChange))
outlying[as.name(names(largestOut))] <- TRUE
outlying <- rep(FALSE,nrow(DataChange))
outlying[as.umeric(names(largestOut))] <- TRUE
outlying[as.numeric(names(largestOut))] <- TRUE
pcaRes <- data.frame(pcaRes,outlying)
autoplot(pcaDat,data = pcaRes , label = TRUE,shape = FALSE,label.label = 'substring',
label.alpha = 0.6,loadings = TRUE,loadings.label = TRUE,color = 'outlying')
autoplot(pcaDat,data = pcaRes , label = TRUE,shape = FALSE,label.label = 'substring',
label.alpha = 0.6,loadings = TRUE,loadings.label = TRUE,label.color = 'outlying')
autoplot(pcaDat,data = pcaRes , label = TRUE,shape = FALSE,label.label = 'substring',
label.alpha = 0.6,loadings = TRUE,loadings.label = TRUE,label.colour = 'outlying')
urf <- randomForest::randomForest(x = DataChange[,-c(1,2)])
out <- randomForest::outlier(urf)
names(out) <- 1:length(out)
largestOut <- sort(out,decreasing = TRUE)[1:5]
outlying <- rep(FALSE,nrow(DataChange))
outlying[as.numeric(names(largestOut))] <- TRUE
pcaRes <- data.frame(pcaRes,outlying)
autoplot(pcaDat,data = pcaRes , label = TRUE,shape = FALSE,label.label = 'substring',
label.alpha = 0.6,loadings = TRUE,loadings.label = TRUE,label.colour = 'outlying')
urf <- randomForest::randomForest(x = DataChange[,-c(1,2)])
out <- randomForest::outlier(urf)
names(out) <- 1:length(out)
largestOut <- sort(out,decreasing = TRUE)[1:5]
outlying <- rep(FALSE,nrow(DataChange))
outlying[as.numeric(names(largestOut))] <- TRUE
pcaRes <- data.frame(pcaRes,outlying)
autoplot(pcaDat,data = pcaRes , label = TRUE,shape = FALSE,label.label = 'substring',
label.alpha = 0.6,loadings = TRUE,loadings.label = TRUE,label.colour = 'outlying')
urf <- randomForest::randomForest(x = DataChange[,-c(1,2)])
out <- randomForest::outlier(urf)
names(out) <- 1:length(out)
largestOut <- sort(out,decreasing = TRUE)[1:5]
DataChange[names(largestOut),1]
outlying <- rep(FALSE,nrow(DataChange))
outlying[as.numeric(names(largestOut))] <- TRUE
pcaRes <- data.frame(pcaRes,outlying)
autoplot(pcaDat,data = pcaRes , label = TRUE,shape = FALSE,label.label = 'substring',
label.alpha = 0.6,loadings = TRUE,loadings.label = TRUE,label.colour = 'outlying')
pcaDat <- DataChange[,-c(1,2)]
pcaDat <- prcomp(pcaDat, scale. = TRUE,center = TRUE)
substring <- substr(DataChange$country,1,2)
pcaRes <- data.frame(DataChange, substring)
urf <- randomForest::randomForest(x = DataChange[,-c(1,2)])
out <- randomForest::outlier(urf)
names(out) <- 1:length(out)
largestOut <- sort(out,decreasing = TRUE)[1:5]
DataChange[names(largestOut),1]
outlying <- rep(FALSE,nrow(DataChange))
outlying[as.numeric(names(largestOut))] <- TRUE
pcaRes2 <- data.frame(pcaRes,outlying)
autoplot(pcaDat,data = pcaRes2 , label = TRUE,shape = FALSE,label.label = 'substring',
label.alpha = 0.6,loadings = TRUE,loadings.label = TRUE,label.colour = 'outlying')
packages <- c("ggplot2","tidyr","pcaMethods","ggfortify","randomForest",'isotree')
if (!requireNamespace("BiocManager", quietly = TRUE)){
install.packages("BiocManager")
BiocManager::install(version = "3.13")
}
for (p in packages){
if (!require(p, character.only = TRUE)){
BiocManager::install(p,update = FALSE)
if(!require(p,character.only = TRUE)) {stop("Package not found")}
}
}
test <- isolation.forest(DataChange[,-c(1,2)])
View(test)
test <- isolation.forest(DataChange[,-c(1,2)],output_score = TRUE)
plot(test[[2]])
#Using unsupervised random forest to identify outliers
#urf <- randomForest::randomForest(x = DataChange[,-c(1,2)])
#out <- randomForest::outlier(urf)
#names(out) <- 1:length(out)
urf <- isolation.forest(DataChange[,-c(1,2)],output_score = TRUE)
out <- urf[[2]]
largestOut <- sort(out,decreasing = TRUE)[1:5]
names(largestOut)
names(out) <- 1:length(out)
largestOut <- sort(out,decreasing = TRUE)[1:5]
names(largestOut)
DataChange[names(largestOut),1]
outlying <- rep(FALSE,nrow(DataChange))
outlying[as.numeric(names(largestOut))] <- TRUE
pcaRes2 <- data.frame(pcaRes,outlying)
autoplot(pcaDat,data = pcaRes2 , label = TRUE,shape = FALSE,label.label = 'substring',
label.alpha = 0.6,loadings = TRUE,loadings.label = TRUE,label.colour = 'outlying')
largestOut <- sort(out,decreasing = TRUE)[1:6]
DataChange[names(largestOut),1]
outlying <- rep(FALSE,nrow(DataChange))
outlying[as.numeric(names(largestOut))] <- TRUE
pcaRes2 <- data.frame(pcaRes,outlying)
autoplot(pcaDat,data = pcaRes2 , label = TRUE,shape = FALSE,label.label = 'substring',
label.alpha = 0.6,loadings = TRUE,loadings.label = TRUE,label.colour = 'outlying')
=======
test <- vector('list',5)
test[[1]] <- rf_1
test[[2]] <- rf_2
View(test)
test2 <- test[[1]][[1]][['test']]
View(test2)
rf <- vector('list',nrow(param))
# rf <- lapply(trainSets,function(trainSet){
#   test <- data[-trainSet,]
#   train <- data[trainSet,]
#   res <- randomForest::randomForest(x = train[,-c(1,ncol(train))],y = train[,ncol(train)],
#                                     ntree = 10,keep.forest = TRUE)
#   return(res)
#
# })
############################################################
#Gathering prediction results
for (i in 1:length(rf)){
rf[[i]] <- eval(parse(text = paste0("rf_",i)))
}
View(rf)
# rf <- lapply(trainSets,function(trainSet){
#   test <- data[-trainSet,]
#   train <- data[trainSet,]
#   res <- randomForest::randomForest(x = train[,-c(1,ncol(train))],y = train[,ncol(train)],
#                                     ntree = 10,keep.forest = TRUE)
#   return(res)
#
# })
############################################################
#Gathering prediction results
cvPredByParam <- vector('list',length = nrow(param))
View(rf)
View(data)
View(RFdata)
rownames(data)[1]
dataTemp <- data[,ncol(data)]
dataTemp <- as.data.frame(data[,ncol(data)])
rep(0,2)
dataTemp <- matrix(rep(0,nrow(data)*nrow(param)),ncol = nrow(param))
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*nrow(param)),ncol = nrow(param)))
i = 1
pSet <- rf[[1]]
#   test <- data[-trainSet,]
#   train <- data[trainSet,]
#   res <- randomForest::randomForest(x = train[,-c(1,ncol(train))],y = train[,ncol(train)],
#                                     ntree = 10,keep.forest = TRUE)
#   return(res)
#
# })
############################################################
#Gathering prediction results
#cvPredByParam <- lapply(rf,function(pSet){
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(nrow(param)),ncol = nrow(param))))
#  for (i in 1:length(RFdata)){
samples <- RFdata[[i]][[2]]
predicted <- pSet[[i]][['test']][['predicted']]
temp <- data.frame(predicted,row.names = samples)
View(temp)
temp <- 1:nrow(data)
temp <- rep(NA,1:nrow(data))
temp <- rep(NA,nrow(data))
temp[samples] <- predicted
# rf <- lapply(trainSets,function(trainSet){
#   test <- data[-trainSet,]
#   train <- data[trainSet,]
#   res <- randomForest::randomForest(x = train[,-c(1,ncol(train))],y = train[,ncol(train)],
#                                     ntree = 10,keep.forest = TRUE)
#   return(res)
#
# })
############################################################
#Gathering prediction results
cvPredByParam <- lapply(rf,function(pSet){
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(length(pSet)),ncol = nrow(param))))
for (i in 1:length(RFdata)){
samples <- RFdata[[i]][[2]]
predicted <- pSet[[i]][['test']][['predicted']]
temp <- rep(NA,nrow(data))
temp[samples] <- predicted
dataTemp[,i] <- temp
}
colnames(dataTemp) <- paste0('p_set_',1:length(pSet))
})
View(cvPredByParam)
# rf <- lapply(trainSets,function(trainSet){
#   test <- data[-trainSet,]
#   train <- data[trainSet,]
#   res <- randomForest::randomForest(x = train[,-c(1,ncol(train))],y = train[,ncol(train)],
#                                     ntree = 10,keep.forest = TRUE)
#   return(res)
#
# })
############################################################
#Gathering prediction results
cvPredByParam <- lapply(rf,function(pSet){
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(length(pSet)),ncol = nrow(param))))
for (i in 1:length(RFdata)){
samples <- RFdata[[i]][[2]]
predicted <- pSet[[i]][['test']][['predicted']]
temp <- rep(NA,nrow(data))
temp[samples] <- predicted
dataTemp[,i] <- temp
}
colnames(dataTemp) <- paste0('p_set_',1:length(pSet))
return(dataTemp)
})
View(cvPredByParam)
# rf <- lapply(trainSets,function(trainSet){
#   test <- data[-trainSet,]
#   train <- data[trainSet,]
#   res <- randomForest::randomForest(x = train[,-c(1,ncol(train))],y = train[,ncol(train)],
#                                     ntree = 10,keep.forest = TRUE)
#   return(res)
#
# })
############################################################
#Gathering prediction results
cvPredByParam <- lapply(rf,function(pSet){
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(length(pSet)),ncol = length(pSet))))
for (i in 1:length(RFdata)){
samples <- RFdata[[i]][[2]]
predicted <- pSet[[i]][['test']][['predicted']]
temp <- rep(NA,nrow(data))
temp[samples] <- predicted
dataTemp[,i] <- temp
}
colnames(dataTemp) <- paste0('p_set_',1:length(pSet))
return(dataTemp)
})
View(cvPredByParam)
length(pSet)
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(length(pSet)),ncol = length(pSet))))
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(length(rf)),ncol = length(rf))))
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(length(rf)),ncol = length(rf))))
dataTemp <- matrix(rep(0,nrow(data)*(length(rf)),ncol = length(rf)))
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(length(rf))),ncol = length(rf)))
# rf <- lapply(trainSets,function(trainSet){
#   test <- data[-trainSet,]
#   train <- data[trainSet,]
#   res <- randomForest::randomForest(x = train[,-c(1,ncol(train))],y = train[,ncol(train)],
#                                     ntree = 10,keep.forest = TRUE)
#   return(res)
#
# })
############################################################
#Gathering prediction results
cvPredByParam <- lapply(rf,function(pSet){
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(length(rf))),ncol = length(rf)))
for (i in 1:length(RFdata)){
samples <- RFdata[[i]][[2]]
predicted <- pSet[[i]][['test']][['predicted']]
temp <- rep(NA,nrow(data))
temp[samples] <- predicted
dataTemp[,i] <- temp
}
colnames(dataTemp) <- paste0('p_set_',1:length(pSet))
return(dataTemp)
})
View(cvPredByParam)
cvPredByParam <- lapply(rf,function(pSet){
dataTemp <- as.data.frame(matrix(rep(0,nrow(data)*(length(rf))),ncol = length(rf)))
for (i in 1:length(RFdata)){
samples <- RFdata[[i]][[2]]
predicted <- pSet[[i]][['test']][['predicted']]
temp <- rep(NA,nrow(data))
temp[samples] <- predicted
dataTemp[,i] <- temp
}
colnames(dataTemp) <- names(RFdata)
return(dataTemp)
})
names(cvPredByParam) <- paste0('p_set_',1:length(pSet))
names(cvPredByParam) <- paste0('p_set_',1:length(rf))
View(cvPredByParam)
View(cvPredByParam[["p_set_1"]])
test <- sd(c(1,5))
test <- sd(cvPredByParam[[1]][1,],na.rm = TRUE)
View(rf_1)
#dat <- "data_change.csv"
dat <- "Data_Y_Y_minus_One.csv" #Which version of the cleaned dataset to be used
nRun <- 10 #Number of separate runs
#-----------------------#
#   Loading libraries   #
#-----------------------#
packages <- c("ggplot2","randomForest","caret","dplyr","tidyr","parallel")
if (!requireNamespace("BiocManager", quietly = TRUE)){
install.packages("BiocManager")
BiocManager::install(version = "3.13")
}
for (p in packages){
if (!require(p, character.only = TRUE)){
BiocManager::install(p,update = FALSE)
if(!require(p,character.only = TRUE)) {stop("Package not found")}
}
}
sample(39,size = 39,replace = TRUE)
save(c(nRun,p),file = "test.RData")
save(nRun,p,file = "test.RData")
load("test.RData")
t <-  load("test.RData")
#------------------#
#   Loading data   #
#------------------#
data <- read.csv(dat)
data <- data[,-1]
#--------------#
#   Analysis   #
#--------------#
set.seed(2021)
#Setting parameter grid
param.mtry <- c(round((ncol(data)-2)/9),
round((ncol(data)-2)/3),
round((ncol(data)-2)/1.5))
param.nodesize <- c(3,5,7)
param.maxnodes <- c(0,10,100)
param <- expand.grid(param.mtry,param.nodesize,param.maxnodes)
#param <- split(param,1:nrow(param))
###############################
#Setting the training and test sets for 50 runs and
trainSets <- vector("list",nRun)
for (i in 1:nRun){
trainSets[[i]] <- caret::groupKFold(group = data$country,k = 39)
names(trainSets[[i]]) <- paste0("Run_",i,"_Fold_",1:length(trainSets[[i]]))
}
#aggregating them for computation efficiency
trainSets <- do.call(c, trainSets)
# testSets <- lapply(trainSets,function(trainSet){testSet <- setdiff(1:nrow(data),trainSet)})
#
# xtest <- lapply(testSets,function(testSet){dat <- data[testSet,-c(1,11)]})
# xtrain <- lapply(trainSets,function(trainSet){dat <- data[trainSet,-c(1,11)]})
# ytest <- lapply(testSets,function(testSet){dat <- data[testSet,11]})
# ytrain <- lapply(trainSets,function(trainSet){dat <- data[trainSet,11]})
RFdata <- lapply(trainSets,function(trainSet){
fold <- vector("list",6)
fold[[1]] <- trainSet
fold[[2]] <- setdiff(1:nrow(data),trainSet)
fold[[3]] <- data[-trainSet,-c(1,11)] #xtest
fold[[4]] <- data[trainSet,-c(1,11)] #xtrain
fold[[5]] <- data[-trainSet,11] #ytest
fold[[6]] <- data[trainSet,11] #ytrain
return(fold)
})
#----------------#
#dat <- "data_change.csv"
dat <- "Data_Y_Y_minus_One.csv" #Which version of the cleaned dataset to be used
nRun <- 2 #Number of separate runs
#-----------------------#
#   Loading libraries   #
#-----------------------#
packages <- c("ggplot2","randomForest","caret","dplyr","tidyr","parallel")
if (!requireNamespace("BiocManager", quietly = TRUE)){
install.packages("BiocManager")
BiocManager::install(version = "3.13")
}
for (p in packages){
if (!require(p, character.only = TRUE)){
BiocManager::install(p,update = FALSE)
if(!require(p,character.only = TRUE)) {stop("Package not found")}
}
}
#------------------#
#   Loading data   #
#------------------#
data <- read.csv(dat)
data <- data[,-1]
#--------------#
#   Analysis   #
#--------------#
set.seed(2021)
#Setting parameter grid
param.mtry <- c(round((ncol(data)-2)/9),
round((ncol(data)-2)/3),
round((ncol(data)-2)/1.5))
param.nodesize <- c(3,5,7)
param.maxnodes <- c(0,10,100)
param <- expand.grid(param.mtry,param.nodesize,param.maxnodes)
#param <- split(param,1:nrow(param))
###############################
#Setting the training and test sets for 50 runs and
trainSets <- vector("list",nRun)
for (i in 1:nRun){
trainSets[[i]] <- caret::groupKFold(group = data$country,k = 39)
names(trainSets[[i]]) <- paste0("Run_",i,"_Fold_",1:length(trainSets[[i]]))
}
#aggregating them for computation efficiency
trainSets <- do.call(c, trainSets)
# testSets <- lapply(trainSets,function(trainSet){testSet <- setdiff(1:nrow(data),trainSet)})
#
# xtest <- lapply(testSets,function(testSet){dat <- data[testSet,-c(1,11)]})
# xtrain <- lapply(trainSets,function(trainSet){dat <- data[trainSet,-c(1,11)]})
# ytest <- lapply(testSets,function(testSet){dat <- data[testSet,11]})
# ytrain <- lapply(trainSets,function(trainSet){dat <- data[trainSet,11]})
RFdata <- lapply(trainSets,function(trainSet){
fold <- vector("list",6)
fold[[1]] <- trainSet
fold[[2]] <- setdiff(1:nrow(data),trainSet)
fold[[3]] <- data[-trainSet,-c(1,11)] #xtest
fold[[4]] <- data[trainSet,-c(1,11)] #xtrain
fold[[5]] <- data[-trainSet,11] #ytest
fold[[6]] <- data[trainSet,11] #ytrain
return(fold)
})
system.time({
coreNum <- parallel::detectCores()
clust <- parallel::makeCluster(coreNum-1)
rf <- vector('list',nrow(param))
for (i in 1:nrow(param)){
print(paste0("Running over parameter set ",i,"..."))
mtry <- as.numeric(param[i,1])
nodesize <- as.numeric(param[i,2])
if (param[i,3] == 0){maxnodes <- NULL}
else{maxnodes <- param[i,3]}
clusterExport(cl = clust,varlist = c("mtry","nodesize","maxnodes"))
rf[[i]] <- parLapply(cl = clust,RFdata,function(fold){
xtest <- fold[[3]]
xtrain <- fold[[4]]
ytest <- fold[[5]]
ytrain <- fold[[6]]
res <- randomForest::randomForest(x = xtrain,y = ytrain,
xtest = xtest,ytest = ytest,
mtry = mtry,nodesize = nodesize,maxnodes = maxnodes,
keep.forest = FALSE,ntree = 20)
return(res)
})
print(paste0("Running over parameter set ",i,"...","DONE"))
#assign(paste0('rf_',i),rf,pos = .GlobalEnv)
}
stopCluster(cl = clust)
})
View(rf)
randomForest::importance(rf[[1]][[1]])
system.time({
coreNum <- parallel::detectCores()
clust <- parallel::makeCluster(coreNum-1)
rf <- vector('list',nrow(param))
for (i in 1:nrow(param)){
print(paste0("Running over parameter set ",i,"..."))
mtry <- as.numeric(param[i,1])
nodesize <- as.numeric(param[i,2])
if (param[i,3] == 0){maxnodes <- NULL}
else{maxnodes <- param[i,3]}
clusterExport(cl = clust,varlist = c("mtry","nodesize","maxnodes"))
rf[[i]] <- parLapply(cl = clust,RFdata,function(fold){
xtest <- fold[[3]]
xtrain <- fold[[4]]
ytest <- fold[[5]]
ytrain <- fold[[6]]
res <- randomForest::randomForest(x = xtrain,y = ytrain,
xtest = xtest,ytest = ytest,
mtry = mtry,nodesize = nodesize,maxnodes = maxnodes,
keep.forest = FALSE,ntree = 20,importance = TRUE)
return(res)
})
print(paste0("Running over parameter set ",i,"...","DONE"))
#assign(paste0('rf_',i),rf,pos = .GlobalEnv)
}
stopCluster(cl = clust)
})
View(rf)
View(RFdata)
View(rf)
randomForest::importance(rf[[1]][[1]])
barplot(randomForest::importance(rf[[1]][[1]])[,2])
>>>>>>> 9991e1ee1b29748f70c2f494ab496594f9862723
